---
title: 'Report 2: Classification'
output:
  html_document:
    df_print: paged
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setting up the work environment (data, packages)
```{r, warning=FALSE, message=FALSE}
setwd("C:/Users/Crystal/Downloads/BUS 212A/final_project")
df <- read.csv("classify_data.csv")

## Running Packages
library(dplyr)
library(nnet)
library(fastDummies)
library(caret)
library(class)
str(data)

# Wrangling Data
data <- subset(df, select = -c(X)) # removing useless variables
data$Cancer.Site <- as.factor(data$Cancer.Site) # factorizing cancer site variable
data$Year <- as.factor(data$Year) # factorizing year variable
data$Sex <- as.factor(data$Sex) # factorizing sex variable
data$Incidence.and.Survival.Assumptions <- as.factor(data$Incidence.and.Survival.Assumptions) # factorizing incidence
data$Year.transformed <- as.numeric(data$Year)
data$YearxCost.Increase <- data$Year.transformed * data$Annual.Cost.Increase..applied.to.initial.and.last.phases. # interaction term between annual cost increase and year
data <- subset(data, select = -c(Year.transformed))
ndata <- dummy_cols(data, select_columns = c('Cancer.Site'), remove_selected_columns = TRUE) # creating dummy variables for Cancer.Site
fdata <- subset(ndata, select = -c(Cancer.Site_Bladder, Cancer.Site_Brain, Cancer.Site_Breast, Cancer.Site_Cervix, Cancer.Site_Colorectal, Cancer.Site_Esophagus, Cancer.Site_Head_Neck, Cancer.Site_Kidney, Cancer.Site_Leukemia, Cancer.Site_Lung, Cancer.Site_Lymphoma, Cancer.Site_Melanoma, Cancer.Site_Other, Cancer.Site_Ovary, Cancer.Site_Pancreas, Cancer.Site_Prostate, Cancer.Site_Stomach, Cancer.Site_Uterus)) # Removing non target binary variables, only keeping Cancer.Site_Allsites
str(fdata)
### write.csv(fdata, "C:\\Users\\ca2ha\\Documents\\BUS 212A\\final_project\\classification_final.csv", row.names = TRUE)

```

# Logistic Regression

```{r}
## Partition Data
set.seed(2)
train.index <- sample(c(1:dim(fdata)[1]), dim(fdata)[1]*0.6)
train.df <- fdata[train.index, ]
valid.df <- fdata[-train.index, ]

## Running Logistic Regression
logit_reg <- glm(Cancer.Site_AllSites ~ ., data = train.df, family = "binomial")
options(scipen=999)
summary(logit_reg)

```
```{r}
# Prediction
logit.reg.pred <- predict(logit_reg, valid.df[, -7], type = "response")
# first 10 actual and predicted records
data.frame(actual = valid.df$Cancer.Site_AllSites[1:10], predicted = logit.reg.pred[1:10])

```
```{r}
# Create confusion matrix
confusionMatrix(table(as.numeric(logit.reg.pred>0.5), valid.df$Cancer.Site_AllSites))
```


# KNN Classifier
```{r}
train.norm.df <- train.df
valid.norm.df <- valid.df
mower.norm.df <- fdata
# use preProcess() from the caret package to normalize Income and Lot_Size.
norm.values <- preProcess(train.df[, 1:6], method=c("center", "scale"))
train.norm.df[, 1:6] <- predict(norm.values, train.df[, 1:6])
valid.norm.df[, 1:6] <- predict(norm.values, valid.df[, 1:6])
mower.norm.df[, 1:6] <- predict(norm.values, fdata[, 1:6])  # whole thing
new.norm.df <- predict(norm.values, fdata)

# try transforming data types into numeric for knn function to calculate distances
train.norm.df$Year <- as.numeric(train.norm.df$Year)
train.norm.df$Sex <- as.numeric(train.norm.df$Sex)
train.norm.df$Incidence.and.Survival.Assumptions <- as.numeric(train.norm.df$Incidence.and.Survival.Assumptions)

valid.norm.df$Year <- as.numeric(valid.norm.df$Year)
valid.norm.df$Sex <- as.numeric(valid.norm.df$Sex)
valid.norm.df$Incidence.and.Survival.Assumptions <- as.numeric(valid.norm.df$Incidence.and.Survival.Assumptions)

mower.norm.df$Year <- as.numeric(mower.norm.df$Year)
mower.norm.df$Sex <- as.numeric(mower.norm.df$Sex)
mower.norm.df$Incidence.and.Survival.Assumptions <- as.numeric(mower.norm.df$Incidence.and.Survival.Assumptions)

new.norm.df$Year <- as.numeric(new.norm.df$Year)
new.norm.df$Sex <- as.numeric(new.norm.df$Sex)
new.norm.df$Incidence.and.Survival.Assumptions <- as.numeric(new.norm.df$Incidence.and.Survival.Assumptions)

# use knn() to compute knn. 
# knn() is available in library FNN (provides a list of the nearest neighbors)
# and library class (allows a numerical output variable).

nn <- knn(train = train.norm.df[, 1:6], cl = train.norm.df[, 7], test = new.norm.df[,1:6], k = 3)   # <<<<<<< set k for number of neighbors considered

row.names(train.norm.df)[attr(nn, "nn.index")]




### Table 7.3


# Initialize a data frame with two columns: k, and accuracy.
accuracy.df <- data.frame(k = seq(1, 14, 1), accuracy = rep(0, 14))

# compute knn for different numbers of neighbords (k) on validation.
for(i in 10:55) {          # <<<< adjust the bounds to look at particular confusion matrix
  knn.pred <- knn(train = train.norm.df[, 1:6], cl = train.norm.df[, 7], 
                  test = valid.norm.df[, 1:6], k = i)
  accuracy.df[i, 2] <- confusionMatrix(knn.pred, factor(valid.norm.df[, 7]))$overall[1] 
  
  
}

# which k is the best?
accuracy.df

# We pick k = 35 to avoid overfitting

# How can we examine the confusion matrix for that k, comparing the predicted class vs. actual class?
# We want only a knn.pred vector of predictinos for a specific value of k
#
for(i in 30:35) {  # <<<< adjust the bounds to look only at confusion matrix with specific k
  knn.pred <- knn(train = train.norm.df[, 1:6], cl = train.norm.df[, 7], 
                  test = valid.norm.df[, 1:6], k = i)
  accuracy.df[i, 2] <- confusionMatrix(knn.pred, factor(valid.norm.df[, 7]))$overall[1] 
  
  
}

confusionMatrix(knn.pred, factor(valid.norm.df[, 7]))


```